---
title: "p8105_hw2_xz2788"
author: "Xiaoyue Zhang"
date: "9/26/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading packages

```{r loading_package, results='hide', message=FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

Import and tidy data:

```{r import_data}
transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
                        col_types = "cccddccccccccccccccccclclcccddcc") %>% janitor::clean_names()
```

Look at the data first:

```{r view_data, eval=FALSE}
View(transit_data)
head(transit_data)
tail(transit_data)
str(transit_data)
skimr::skim(transit_data)
```

Select the data needed:

```{r select_data}
transit_data_clean = select(transit_data, line:entry, vending, ada)
```

Convert "entry" and "vending" into logical variables:

```{r convert_to_logical_vector}
transit_data_clean$entry = ifelse(transit_data_clean$entry == "YES", TRUE, FALSE)
transit_data_clean$vending = ifelse(transit_data_clean$vending == "YES", TRUE, FALSE)
```

Remove duplicated rows by station name and line:

```{r}
transit_data_clean = distinct(transit_data_clean, station_name, line, .keep_all = TRUE)
```

Review this new dataset:

```{r overview_new_data, eval=FALSE}
str(transit_data_clean)
View(transit_data_clean)
```

Get the dimension of the new dataset

```{r dimension}
dim(transit_data_clean)
```

Description of this dataset:

This dataset contains 19 variables and 465 records (stations). The variables include line, station name as well as its location, the routes served at that station, entry and its type, vending and ADA compliance. Station location (latitude/longitude) are numeric variables, "entry", "vending" and "ada" are logical variables. All of the others are character variables.

Process of data cleaning:

Firstly specifying the column type when importing the data then I used janitor::clean_names to clean tha names. After looking at data, I selected the variables needed to a new dataset and converted "entry" and "vending" variables into logical ones for future analysis. Lastly, I've removed all the duplicated rows from the dataset since we only had to focus on the entry of each station other than the mutiple exits from each station.

The dimension of this dataset is 465 * 19. This is not yet a tidy data since the routs served at each station should be classified into each train route instead of just enumerating.

## Answer the related questions in HW2

```{r count_rows}
nrow(transit_data_clean)
```

1. There are in total 465 distinct stations in the data.

```{r filter_ada_compliant}
filter(transit_data_clean, ada == TRUE) %>% nrow()
```

2. There are 84 stations are ADA compliant.

```{r proportion_with_conditions}
mean(transit_data_clean$entry == TRUE & transit_data_clean$vending == FALSE)
```

3. The proportion of station entrances / exits without vending allow entrance is 0.01.

## Reformating data

Make route number and route name two distinct variables:

```{r reformat}
transit_data_reformat = gather(transit_data_clean, key = route_number, value = route_name, route1:route11)
```

Filter the rows and remove duplicated ones:

```{r filter_A_train}
filter(transit_data_reformat, route_name == "A") %>% distinct(station_name, line, .keep_all = TRUE) %>% nrow()
```

```{r count_ada_compliant}
filter(transit_data_reformat, route_name == "A") %>% distinct(station_name, line, .keep_all = TRUE) %>% filter(ada == TRUE) %>% nrow()
```

Therefore, 60 distinct stations serve the A train and 17 of these are ADA compliant.

# Problem 2

Import and tidy the Mr. Trash Wheel sheet:
### Why can't I directly select A:N
```{r tidy_sheet_1}
trash_wheel_data = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", range = "A2:N258", sheet = 1) %>%
  janitor::clean_names() %>% 
  rename(weight = weight_tons, volume = volume_cubic_yards) %>% 
  filter(!is.na(dumpster))
```

Round the number of sports balls and convert into an integer variable:

```{r convert_sports_balls}
trash_wheel_data$sports_balls = round(trash_wheel_data$sports_balls) %>% 
as.integer(trash_wheel_data$sports_balls)
```

Look at the data first:

```{r review_data, eval = FALSE}
View(trash_wheel_data)
str(trash_wheel_data)
head(trash_wheel_data)
tail(trash_wheel_data)
skimr::skim(trash_wheel_data)
```

Import and tidy precipitation data for 2016 and 2017:

```{r tidy_precipitation_sheet_2017}
precipit_data_2017 = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 3) %>% 
  janitor::clean_names() %>% 
  rename(month = precipitation_in, precipitation = x_1) %>% 
  na.omit() %>% 
  mutate(year = "2017")
precipit_data_2017$precipitation = as.numeric(precipit_data_2017$precipitation)
precipit_data_2017 = precipit_data_2017[-1,]
precipit_data_2017$precipitation = round(precipit_data_2017$precipitation, digits = 2)
precipit_data_2017$month = month.name[1:8]
```

```{r tidy_precipitation_sheet_2016}
precipit_data_2016 = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 4) %>% 
  janitor::clean_names() %>% 
  rename(month = precipitation_in, precipitation = x_1) %>% 
  na.omit() %>% 
  mutate(year = "2016")
precipit_data_2016$precipitation = as.numeric(precipit_data_2016$precipitation)
precipit_data_2016 = precipit_data_2016[-1,]
precipit_data_2016$precipitation = round(precipit_data_2016$precipitation, digits = 2)
precipit_data_2016$month = month.name  
```

Combine datasets:

```{r combine_datasets}
precipit_data = bind_rows(precipit_data_2016, precipit_data_2017)
```

Describe these datasets:

The "trash_wheel_data" consists of `r ncol(trash_wheel_data)` variables and `r nrow(trash_wheel_data)` observations. These variables are "`r names(trash_wheel_data)`", mainly documenting weight and date of trash and its types.

The "precipit_data" consists of `r ncol(precipit_data)` variables and `r nrow(precipit_data)` observations. The key variables are precipitation in each month of 2016 and 2017. The total precipitation in 2017 is `r sum(precipit_data[which(precipit_data[,3] == 2017), 2])` and the median number of sports balls in a dumpster in 2016 is `r median(filter(trash_wheel_data, year == 2016)$sports_balls)`.

# Problem 3

Loading package

```{r loading_data, results = 'hide', message = FALSE}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
library(readr)
```

View the data first:

```{r overview_data, results = 'hide'}
str(brfss_smart2010)
head(brfss_smart2010)
tail(brfss_smart2010)
skimr::skim(brfss_smart2010)
```


```{r tidy_data}
brfss_smart2010_tidy = janitor::clean_names(brfss_smart2010) %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size) %>% 
  select(year:data_value) %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(more_than_good = excellent + very_good)
```

Answering questions:

There are `r nrow(brfss_smart2010_tidy)` unique locations in the dataset.

```{r number_of_states}
distinct(brfss_smart2010_tidy, state, .keep_all = TRUE) %>% 
  nrow()
```

```{r most_observed_state}
count_(brfss_smart2010_tidy, "state", sort = TRUE)
```

```{r median_2002_response}
data_2002 = filter(brfss_smart2010_tidy, year == 2002)
median(data_2002$excellent, na.rm = TRUE)
```

There are 51 states in the dataset, so every state is represented. NJ is observed most.
The median of the “Excellent” response value in 2002 is 23.6.

Making plots:

```{r histogram_plot}
ggplot(data_2002, aes(x = excellent)) + geom_histogram()
```

```{r scatter_plot}
filter(brfss_smart2010_tidy, county %in% c("NY - New York County", "NY - Queens County")) %>% 
  ggplot(aes(x = excellent, y = year)) +
  geom_point(aes(color = county))
```

